### 66DaysOfData - Day 35

# Sequence Modeling: Recurrent and Recursive Nets

## Deep Learning Chapter 10

Recurrent neural networks (RNNs) are a family of neural networks for processing sequential data. 

RNN can scale to much longer sequences than would be practical for networks without sequence-based specialisation.

The pre-requisite for recurrent networks: Parameter sharing. 

A simple fully connected feedforward network could not deal with sentences with different lengths, neither deal with the position change of words in sentences.

Compare to Convolution across a 1-D temporal seuqnce. "The convolution operation allows a network to share parameters across time, but is shallow"

For RNN, each member of the output is produced using the same update rule applied to the previous outputs. Each member of the output is produced using the same update rule applied to the previous outputs.



